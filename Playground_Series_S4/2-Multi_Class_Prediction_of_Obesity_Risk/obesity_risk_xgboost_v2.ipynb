{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "\n",
    "# STATISTICS\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# turn of warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_original = pd.read_csv('data/ObesityDataSet.csv')\n",
    "df_test = pd.read_csv('data/test.csv', index_col='id')\n",
    "\n",
    "df = pd.concat((df_train, df_original), axis=0).drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.443011</td>\n",
       "      <td>1.699998</td>\n",
       "      <td>81.669950</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.983297</td>\n",
       "      <td>2.763573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.711460</td>\n",
       "      <td>50.165754</td>\n",
       "      <td>1.880534</td>\n",
       "      <td>1.411685</td>\n",
       "      <td>1.910378</td>\n",
       "      <td>0.866045</td>\n",
       "      <td>1.673584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.952737</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.274851</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.674061</td>\n",
       "      <td>1.467863</td>\n",
       "      <td>0.780199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.641081</td>\n",
       "      <td>1.914186</td>\n",
       "      <td>93.798055</td>\n",
       "      <td>2.679664</td>\n",
       "      <td>1.971472</td>\n",
       "      <td>1.979848</td>\n",
       "      <td>1.967973</td>\n",
       "      <td>0.931721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>20.976842</td>\n",
       "      <td>1.710730</td>\n",
       "      <td>131.408528</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.728139</td>\n",
       "      <td>1.676269</td>\n",
       "      <td>0.906247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>21.982942</td>\n",
       "      <td>1.748584</td>\n",
       "      <td>133.742943</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.005130</td>\n",
       "      <td>1.341390</td>\n",
       "      <td>0.599270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>22.524036</td>\n",
       "      <td>1.752206</td>\n",
       "      <td>133.689352</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.054193</td>\n",
       "      <td>1.414209</td>\n",
       "      <td>0.646288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2109</th>\n",
       "      <td>24.361936</td>\n",
       "      <td>1.739450</td>\n",
       "      <td>133.346641</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.852339</td>\n",
       "      <td>1.139107</td>\n",
       "      <td>0.586035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>23.664709</td>\n",
       "      <td>1.738836</td>\n",
       "      <td>133.472641</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.863513</td>\n",
       "      <td>1.026452</td>\n",
       "      <td>0.714137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22869 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Age    Height      Weight      FCVC       NCP      CH2O       FAF  \\\n",
       "0     24.443011  1.699998   81.669950  2.000000  2.983297  2.763573  0.000000   \n",
       "1     18.000000  1.560000   57.000000  2.000000  3.000000  2.000000  1.000000   \n",
       "2     18.000000  1.711460   50.165754  1.880534  1.411685  1.910378  0.866045   \n",
       "3     20.952737  1.710730  131.274851  3.000000  3.000000  1.674061  1.467863   \n",
       "4     31.641081  1.914186   93.798055  2.679664  1.971472  1.979848  1.967973   \n",
       "...         ...       ...         ...       ...       ...       ...       ...   \n",
       "2106  20.976842  1.710730  131.408528  3.000000  3.000000  1.728139  1.676269   \n",
       "2107  21.982942  1.748584  133.742943  3.000000  3.000000  2.005130  1.341390   \n",
       "2108  22.524036  1.752206  133.689352  3.000000  3.000000  2.054193  1.414209   \n",
       "2109  24.361936  1.739450  133.346641  3.000000  3.000000  2.852339  1.139107   \n",
       "2110  23.664709  1.738836  133.472641  3.000000  3.000000  2.863513  1.026452   \n",
       "\n",
       "           TUE  \n",
       "0     0.976473  \n",
       "1     1.000000  \n",
       "2     1.673584  \n",
       "3     0.780199  \n",
       "4     0.931721  \n",
       "...        ...  \n",
       "2106  0.906247  \n",
       "2107  0.599270  \n",
       "2108  0.646288  \n",
       "2109  0.586035  \n",
       "2110  0.714137  \n",
       "\n",
       "[22869 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.drop('NObeyesdad', axis=1)\n",
    "labels = pd.DataFrame(df['NObeyesdad'])\n",
    "\n",
    "mask_numeric = features.dtypes == float\n",
    "df_numerical = features.loc[:, mask_numeric]\n",
    "\n",
    "df_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Female    11465\n",
      "Male      11404\n",
      "Name: count, dtype: int64\n",
      "family_history_with_overweight\n",
      "yes    18740\n",
      "no      4129\n",
      "Name: count, dtype: int64\n",
      "FAVC\n",
      "yes    20848\n",
      "no      2021\n",
      "Name: count, dtype: int64\n",
      "CAEC\n",
      "Sometimes     19294\n",
      "Frequently     2714\n",
      "Always          531\n",
      "no              330\n",
      "Name: count, dtype: int64\n",
      "SMOKE\n",
      "no     22580\n",
      "yes      289\n",
      "Name: count, dtype: int64\n",
      "SCC\n",
      "no     22086\n",
      "yes      783\n",
      "Name: count, dtype: int64\n",
      "CALC\n",
      "Sometimes     16467\n",
      "no             5802\n",
      "Frequently      599\n",
      "Always            1\n",
      "Name: count, dtype: int64\n",
      "MTRANS\n",
      "Public_Transportation    18267\n",
      "Automobile                3991\n",
      "Walking                    523\n",
      "Motorbike                   49\n",
      "Bike                        39\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "mask_categorical = features.dtypes != float\n",
    "df_categorical = features.loc[:, mask_categorical]\n",
    "\n",
    "for i in range(df_categorical.shape[1]):\n",
    "    print(df_categorical.iloc[:, i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_categorical.copy(deep=True)\n",
    "\n",
    "# label encoding\n",
    "df_encoded['Gender'] = df_categorical['Gender'].map({'Male':0, 'Female':1})\n",
    "df_encoded['family_history_with_overweight'] = df_categorical['family_history_with_overweight'].map({'no':0, 'yes':1})\n",
    "df_encoded['FAVC'] = df_categorical['FAVC'].map({'no':0, 'yes':1})\n",
    "df_encoded['CAEC'] = df_categorical['CAEC'].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "df_encoded['SMOKE'] = df_categorical['SMOKE'].map({'no':0, 'yes':1})\n",
    "df_encoded['SCC'] = df_categorical['SCC'].map({'no':0, 'yes':1})\n",
    "df_encoded['CALC'] = df_categorical['CALC'].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "\n",
    "# one-hot encoding\n",
    "df_onehot = pd.get_dummies(df_categorical['MTRANS']).astype(int)\n",
    "df_encoded.drop('MTRANS', axis=1, inplace=True)\n",
    "\n",
    "# concatenate\n",
    "# one feature of df_encoded is redundant; we can remove it\n",
    "df_encoded = pd.concat([df_encoded, df_onehot.iloc[:, 0:-1]], axis=1)\n",
    "\n",
    "#df_encoded\n",
    "df_all_features = pd.concat([df_numerical, df_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preprocessing(data):\n",
    "    features = data.copy(deep=True)\n",
    "\n",
    "    # numerical dataframe\n",
    "    mask_numeric = features.dtypes == float\n",
    "    df_numerical = features.loc[:, mask_numeric]\n",
    "\n",
    "    # categorical dataframe\n",
    "    mask_categorical = features.dtypes != float\n",
    "    df_categorical = features.loc[:, mask_categorical]\n",
    "\n",
    "    # label encoding\n",
    "    df_encoded = df_categorical.copy(deep=True)\n",
    "    df_encoded['Gender'] = df_categorical['Gender'].map({'Male':0, 'Female':1})\n",
    "    df_encoded['family_history_with_overweight'] = df_categorical['family_history_with_overweight'].map({'no':0, 'yes':1})\n",
    "    df_encoded['FAVC'] = df_categorical['FAVC'].map({'no':0, 'yes':1})\n",
    "    df_encoded['CAEC'] = df_categorical['CAEC'].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "    df_encoded['SMOKE'] = df_categorical['SMOKE'].map({'no':0, 'yes':1})\n",
    "    df_encoded['SCC'] = df_categorical['SCC'].map({'no':0, 'yes':1})\n",
    "    df_encoded['CALC'] = df_categorical['CALC'].map({'no':0, 'Sometimes':1, 'Frequently':2, 'Always':3})\n",
    "\n",
    "    # one-hot encoding\n",
    "    df_onehot = pd.get_dummies(df_categorical['MTRANS']).astype(int)\n",
    "    df_encoded.drop('MTRANS', axis=1, inplace=True)\n",
    "\n",
    "    # concatenate\n",
    "    # one feature of df_encoded is redundant; we can remove it\n",
    "    df_encoded = pd.concat([df_encoded, df_onehot.iloc[:, 0:-1]], axis=1)\n",
    "\n",
    "    df_all_features = pd.concat([df_numerical, df_encoded], axis=1)\n",
    "\n",
    "    return df_all_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns Index(['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE',\n",
      "       'Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE',\n",
      "       'SCC', 'CALC', 'Automobile', 'Bike', 'Motorbike',\n",
      "       'Public_Transportation'],\n",
      "      dtype='object')\n",
      "Test columns Index(['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF', 'TUE',\n",
      "       'Gender', 'family_history_with_overweight', 'FAVC', 'CAEC', 'SMOKE',\n",
      "       'SCC', 'CALC', 'Automobile', 'Bike', 'Motorbike',\n",
      "       'Public_Transportation'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_test = apply_preprocessing(df_test)\n",
    "\n",
    "print('Train columns', df_all_features.columns)\n",
    "print('Test columns', df_test.columns)\n",
    "\n",
    "assert all(df_test.columns ==  df_all_features.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels['NObeyesdad'].unique()\n",
    "\n",
    "labels_encoded = labels.copy(deep=True)\n",
    "\n",
    "dict_conversion = {'Insufficient_Weight':0,\n",
    "                   'Normal_Weight':1,\n",
    "                   'Overweight_Level_I':2,\n",
    "                   'Overweight_Level_II':3,\n",
    "                   'Obesity_Type_I':4,\n",
    "                   'Obesity_Type_II':5,\n",
    "                   'Obesity_Type_III':6}\n",
    "\n",
    "labels_encoded['NObeyesdad'] = labels_encoded['NObeyesdad'].map(dict_conversion)\n",
    "#labels_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples 22869\n",
      "Number of featires 19\n"
     ]
    }
   ],
   "source": [
    "X = df_all_features\n",
    "y = np.ravel(labels_encoded)\n",
    "\n",
    "# compare train and test data\n",
    "X_test = df_test\n",
    "assert all(X_test.columns == X.columns), \"Columns of training and test data must be the same\"\n",
    "\n",
    "print('Number of samples', len(X))\n",
    "print('Number of featires', X.shape[1])\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y,\n",
    "                                                                test_size=0.2,\n",
    "                                                                random_state=42,\n",
    "                                                                stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# calculate class weights based on the training data\n",
    "class_weights = compute_class_weight('balanced',\n",
    "                                     classes=np.unique(y),\n",
    "                                     y=y)\n",
    "\n",
    "class_weights = dict(zip(np.unique(y), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.1688729874776387,\n",
       " 1: 0.9697239536954586,\n",
       " 2: 1.2024291497975708,\n",
       " 3: 1.1618065433854907,\n",
       " 4: 1.0018399264029438,\n",
       " 5: 0.9215796897038082,\n",
       " 6: 0.7475972540045767}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='auto', random_state=0, reg_alpha=0, ...)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = GradientBoostingClassifier()\n",
    "clf2 = RandomForestClassifier(class_weight='balanced')\n",
    "clf3 = XGBClassifier()\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf):\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_validation)\n",
    "    train_score = np.mean(y_pred_train == y_train)\n",
    "    validation_score = np.mean(y_pred_test == y_validation)\n",
    "\n",
    "    print('Train score', round(train_score, 3))\n",
    "    print('Test score', round(validation_score, 3))\n",
    "\n",
    "    if train_score - validation_score > 0.05:\n",
    "        print('Overfitting detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Train score 0.925\n",
      "Test score 0.912\n",
      "Random Forest\n",
      "Train score 1.0\n",
      "Test score 0.908\n",
      "Overfitting detected\n",
      "XGBoost\n",
      "Train score 0.988\n",
      "Test score 0.915\n",
      "Overfitting detected\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting')\n",
    "evaluate_model(clf1)\n",
    "\n",
    "print('Random Forest')\n",
    "evaluate_model(clf2)\n",
    "\n",
    "print('XGBoost')\n",
    "evaluate_model(clf3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth', 4, 10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 500, 2000)\n",
    "    gamma = trial.suggest_float('gamma', 0, 1)\n",
    "    reg_alpha = trial.suggest_float('reg_alpha', 0, 1)\n",
    "    reg_lambda = trial.suggest_float('reg_lambda', 0, 1)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 0, 10)\n",
    "    subsample = trial.suggest_float('subsample', 0, 1)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0, 1)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0, 1)\n",
    "\n",
    "    print('Training the model with', X.shape[1], 'features')\n",
    "\n",
    "    params = {'n_estimators': n_estimators,\n",
    "              'learning_rate': learning_rate,\n",
    "              'gamma': gamma,\n",
    "              'reg_alpha': reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'max_depth': max_depth,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'eval_metric':'mlogloss'}\n",
    "\n",
    "    clf = XGBClassifier(**params)\n",
    "\n",
    "    cv_results = cross_validate(clf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "    validation_score = np.mean(cv_results['test_score'])\n",
    "\n",
    "    return validation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-07 14:21:13,191] A new study created in memory with name: no-name-043a5544-b723-4829-84ce-85d51e71f2da\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 19 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-07 14:22:19,809] Trial 0 finished with value: 0.9031008416064672 and parameters: {'max_depth': 9, 'n_estimators': 593, 'gamma': 0.8440523497390293, 'reg_alpha': 0.7807865231039206, 'reg_lambda': 0.38470239671907536, 'min_child_weight': 10, 'subsample': 0.5142767549260333, 'colsample_bytree': 0.35515170869620516, 'learning_rate': 0.9017722054372702}. Best is trial 0 with value: 0.9031008416064672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 19 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-07 14:22:49,236] Trial 1 finished with value: 0.8597229264639668 and parameters: {'max_depth': 4, 'n_estimators': 501, 'gamma': 0.7022943357667949, 'reg_alpha': 0.9435489316422072, 'reg_lambda': 0.43784011596067496, 'min_child_weight': 1, 'subsample': 0.02215628848882878, 'colsample_bytree': 0.7365001660165138, 'learning_rate': 0.4667520726849561}. Best is trial 0 with value: 0.9031008416064672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 19 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-07 14:25:58,911] Trial 2 finished with value: 0.8760335063003115 and parameters: {'max_depth': 8, 'n_estimators': 1047, 'gamma': 0.9293849562331639, 'reg_alpha': 0.19840982997098489, 'reg_lambda': 0.843108490952849, 'min_child_weight': 5, 'subsample': 0.0974695961481501, 'colsample_bytree': 0.5331861514769544, 'learning_rate': 0.6536108718438252}. Best is trial 0 with value: 0.9031008416064672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 19 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-07 14:26:50,008] Trial 3 finished with value: 0.8916438772816356 and parameters: {'max_depth': 5, 'n_estimators': 1609, 'gamma': 0.24269498288430624, 'reg_alpha': 0.4929508968829117, 'reg_lambda': 0.2759483198928736, 'min_child_weight': 10, 'subsample': 0.11336744181551273, 'colsample_bytree': 0.005978537719118271, 'learning_rate': 0.5206159000706477}. Best is trial 0 with value: 0.9031008416064672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 19 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-07 14:28:10,719] Trial 4 finished with value: 0.8932617363699462 and parameters: {'max_depth': 8, 'n_estimators': 1875, 'gamma': 0.9005475195931154, 'reg_alpha': 0.3198647235132195, 'reg_lambda': 0.7482187838975902, 'min_child_weight': 6, 'subsample': 0.22676624678791446, 'colsample_bytree': 0.06113026342459282, 'learning_rate': 0.6651292989488645}. Best is trial 0 with value: 0.9031008416064672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 19 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-07 14:31:08,300] Trial 5 finished with value: 0.892387801979471 and parameters: {'max_depth': 9, 'n_estimators': 1834, 'gamma': 0.34113488591745655, 'reg_alpha': 0.07454577724370515, 'reg_lambda': 0.6275650338643323, 'min_child_weight': 2, 'subsample': 0.32008072432418977, 'colsample_bytree': 0.27741958143115486, 'learning_rate': 0.7505638224296701}. Best is trial 0 with value: 0.9031008416064672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model with 19 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-07 14:36:34,960] Trial 6 finished with value: 0.9006959443611677 and parameters: {'max_depth': 8, 'n_estimators': 1415, 'gamma': 0.671908884565877, 'reg_alpha': 0.5523817368838536, 'reg_lambda': 0.4016793421392031, 'min_child_weight': 0, 'subsample': 0.30941298201193435, 'colsample_bytree': 0.728864528133102, 'learning_rate': 0.4480377489820614}. Best is trial 0 with value: 0.9031008416064672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  7\n",
      "Best trial:\n",
      "  Value: 0.9031008416064672\n",
      "  Params: \n",
      "    max_depth: 9\n",
      "    n_estimators: 593\n",
      "    gamma: 0.8440523497390293\n",
      "    reg_alpha: 0.7807865231039206\n",
      "    reg_lambda: 0.38470239671907536\n",
      "    min_child_weight: 10\n",
      "    subsample: 0.5142767549260333\n",
      "    colsample_bytree: 0.35515170869620516\n",
      "    learning_rate: 0.9017722054372702\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50, timeout=600)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params['eval_metric'] = 'mlogloss'\n",
    "best_params['use_label_encoder'] = False\n",
    "\n",
    "clf = XGBClassifier(**best_params)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'n_estimators': 593,\n",
       " 'gamma': 0.8440523497390293,\n",
       " 'reg_alpha': 0.7807865231039206,\n",
       " 'reg_lambda': 0.38470239671907536,\n",
       " 'min_child_weight': 10,\n",
       " 'subsample': 0.5142767549260333,\n",
       " 'colsample_bytree': 0.35515170869620516,\n",
       " 'learning_rate': 0.9017722054372702,\n",
       " 'eval_metric': 'mlogloss',\n",
       " 'use_label_encoder': False}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20758</td>\n",
       "      <td>Obesity_Type_II</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20759</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20760</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20761</td>\n",
       "      <td>Obesity_Type_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20762</td>\n",
       "      <td>Obesity_Type_III</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id          NObeyesdad\n",
       "0  20758     Obesity_Type_II\n",
       "1  20759  Overweight_Level_I\n",
       "2  20760    Obesity_Type_III\n",
       "3  20761      Obesity_Type_I\n",
       "4  20762    Obesity_Type_III"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_dict_conversion = dict(zip(dict_conversion.values(), dict_conversion.keys()))\n",
    "\n",
    "df_submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "df_submission['NObeyesdad'] = y_pred\n",
    "df_submission['NObeyesdad'] = df_submission['NObeyesdad'].map(reverse_dict_conversion)\n",
    "\n",
    "df_submission.to_csv('data/submission4.csv', index=False)\n",
    "df_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
